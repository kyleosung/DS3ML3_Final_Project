{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import chess_SL_E6_lib as lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import chess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NUM = 6\n",
    "MODEL_VERSION = 3\n",
    "\n",
    "path = \"../Data/DataTrain\"\n",
    "\n",
    "csv_files1 = glob.glob(f'{path}/Chess_Jan_g*') + glob.glob(f'{path}/Chess_Jan_h*') + glob.glob(f'{path}/Chess_Jan_i*') + glob.glob(f'{path}/Chess_Jan_j*') + glob.glob(f'{path}/Chess_Jan_k*')\n",
    "csv_files2 = glob.glob(f'{path}/Chess_Jan_e*') + glob.glob(f'{path}/Chess_Jan_f*')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "dataset1 = lib.ChessIterableDataset(csv_files1, chunksize = 50000)\n",
    "dataset2 = lib.ChessIterableDataset(csv_files2, chunksize = 50000)\n",
    "\n",
    "# Create a data loader\n",
    "train_data_loader = DataLoader(dataset1, batch_size = 25000)\n",
    "val_data_loader = DataLoader(dataset2, batch_size = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training!\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(f'models_EL/model_E6-2.pth', map_location=device)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss() # nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.035, momentum=0.9)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.006)\n",
    "\n",
    "# Train the model\n",
    "training_loss_history, validation_loss_history = lib.train(model, train_data_loader, val_data_loader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'model_E{MODEL_NUM}-{MODEL_VERSION}.pth')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(training_loss_history, label = 'Training Loss')\n",
    "plt.plot(validation_loss_history, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim(0, None)\n",
    "plt.title(f'Figure 1: Loss for E{MODEL_NUM}-{MODEL_VERSION} Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(f'Loss_E{MODEL_NUM}-{MODEL_VERSION}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(training_loss_history, open(f'pickle/training_loss_history_E{MODEL_NUM}-{MODEL_VERSION}.pkl', 'wb'))\n",
    "pickle.dump(validation_loss_history, open(f'pickle/validation_loss_history_E{MODEL_NUM}-{MODEL_VERSION}.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import chess_SL_E8_lib as lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import chess\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NUM = 8\n",
    "MODEL_VERSION = 1\n",
    "\n",
    "path = \"../Data/DataTrain\"\n",
    "\n",
    "letters_in = 'abcdefghijklmnopqrstuvwxyz'\n",
    "letters_out = 'adhlptwz'\n",
    "\n",
    "csv_files1 = []\n",
    "csv_files2 = []\n",
    "\n",
    "for let in letters_in:\n",
    "    csv_files1.extend(glob.glob(f'{path}/Chess_Jan_{let}*'))\n",
    "\n",
    "for let_ in letters_out:\n",
    "    csv_files2.extend(glob.glob(f'{path}/Chess_Jan_{let_}*'))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models Trained\n",
    "- V1 -> Predictor: tensor [64,64]\n",
    "- V2 -> Predictor: tensor [64,64]\n",
    "- V3 -> Predictor: tensor [64,64]\n",
    "- V4 -> Predictor: tensor [64,64]\n",
    "\n",
    "- E1 -> Epochs: 200, SGD(Learning Rate: 0.030, Momentum = 0.9), Loss: L1Loss, Training: \"a*\", Validation: \"a*\" |||| Vars: FEN, white_active, is_check |||| Predictor: CP\n",
    "- E2 -> Epochs: 200, SGD(Learning Rate: 0.035, Momentum = 0.9), Loss: L1Loss, Training: \"a*\", Validation: \"b*\" |||| Vars: FEN, white_active, is_check |||| Predictor: CP\n",
    "- E3 -> Epochs: 75, Adam(Learning Rate: 0.006, Mometum = 0.9), Loss: L1Loss, Training: \"a|b*\", Validation: \"c|d*\" |||| Vars: FEN, white_active, is_check, is_capture |||| Predictor: CP\n",
    "- E3.1 -> Epochs: 50, Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c*\", Validation: \"d|e|f*\" |||| Vars: FEN, white_active, is_check, is_capture |||| Predictor: CP\n",
    "- E3.2 -> Epochs: 40, Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d*\", Validation: \"d|e|f|g*\" |||| Vars: FEN, white_active, is_check, is_capture |||| Predictor: CP\n",
    "- E4.1 -> Epochs: 25, Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d*\", Validation: \"d|e|f|g*\" |||| Vars: FEN, white_active, is_capture |||| Predictor: CP\n",
    "- E5.1 -> Epochs: 25, NN(1 conv, 2 FC), Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d*\", Validation: \"d|e*\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E5.2 -> Epochs: 50, NN(1 conv, 2 FC), Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d|e*\", Validation: \"e|f*\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E6.1 -> Epochs: 25, NN(2 conv, 2 FC), Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d*\", Validation: \"d|e*\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E6.2 -> Epochs: 50, NN(2 conv, 2 FC), Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d|e*\", Validation: \"e|f*\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E7.1 (loaded from 6.2) -> Epochs: 30, NN(2 conv, 2 FC), Adam(Learning Rate: 0.0061), Loss: L1Loss, Training: \"abcdefghijklmnopqr\", Validation: \"adhlp\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E7.2 (loaded from 7.1) -> Epochs: 30, NN(2 conv, 2 FC), Adam(Learning Rate: 0.0061), Loss: L1Loss, Training: \"abcdefghijklmnopqrstuv\", Validation: \"adhlptw\" |||| Vars: FEN |||| Predictor: CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training! (on cuda)\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset\n",
    "dataset1 = lib.ChessIterableDataset(csv_files1)\n",
    "dataset2 = lib.ChessIterableDataset(csv_files2)\n",
    "\n",
    "# Create a data loader\n",
    "train_data_loader = DataLoader(dataset1, batch_size = 25000)\n",
    "val_data_loader = DataLoader(dataset2, batch_size = 25000)\n",
    "\n",
    "# Create a model\n",
    "model = lib.EvalNet()\n",
    "# model = torch.load(f'./models_EL/model_E7-1.pth')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss() # nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.035, momentum=0.9)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0061)\n",
    "\n",
    "# Train the model\n",
    "training_loss_history, validation_loss_history = lib.train(model, train_data_loader, val_data_loader, criterion, optimizer, num_epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'model_E{MODEL_NUM}-{MODEL_VERSION}.pth')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(training_loss_history, label = 'Training Loss')\n",
    "plt.plot(validation_loss_history, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim(0, None)\n",
    "plt.title(f'Figure 1: Loss for E{MODEL_NUM}-{MODEL_VERSION} Model')\n",
    "plt.legend()\n",
    "plt.savefig(f'Loss_E{MODEL_NUM}-{MODEL_VERSION}.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE TO SELF - TEST NEW STOCHASTIC PREDICTION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(training_loss_history, open(f'pickle/training_loss_history_E{MODEL_NUM}-{MODEL_VERSION}.pkl', 'wb'))\n",
    "pickle.dump(validation_loss_history, open(f'pickle/validation_loss_history_E{MODEL_NUM}-{MODEL_VERSION}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = torch.load(f'model_E{MODEL_NUM}-{MODEL_VERSION}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move = lib.predict(model_loaded, board.fen())\n",
    "print(move)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board.push_uci(move)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move = lib.predict(model_loaded, board.fen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move = 'e4f6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : make prediction function\n",
    "# TODO : speed up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import chess_SL_E8_lib as lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import chess\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NUM = 8\n",
    "MODEL_VERSION = 1\n",
    "\n",
    "path = \"../Data/DataTrain\"\n",
    "\n",
    "letters_in = 'a'\n",
    "letters_out = 'b'\n",
    "\n",
    "csv_files1 = []\n",
    "csv_files2 = []\n",
    "\n",
    "for let in letters_in:\n",
    "    csv_files1.extend(glob.glob(f'{path}/Chess_Jan_{let}*'))\n",
    "\n",
    "for let_ in letters_out:\n",
    "    csv_files2.extend(glob.glob(f'{path}/Chess_Jan_{let_}*'))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models Trained\n",
    "- V1 -> Predictor: tensor [64,64]\n",
    "- V2 -> Predictor: tensor [64,64]\n",
    "- V3 -> Predictor: tensor [64,64]\n",
    "- V4 -> Predictor: tensor [64,64]\n",
    "\n",
    "- E1 -> Epochs: 200, SGD(Learning Rate: 0.030, Momentum = 0.9), Loss: L1Loss, Training: \"a*\", Validation: \"a*\" |||| Vars: FEN, white_active, is_check |||| Predictor: CP\n",
    "- E2 -> Epochs: 200, SGD(Learning Rate: 0.035, Momentum = 0.9), Loss: L1Loss, Training: \"a*\", Validation: \"b*\" |||| Vars: FEN, white_active, is_check |||| Predictor: CP\n",
    "- E3 -> Epochs: 75, Adam(Learning Rate: 0.006, Mometum = 0.9), Loss: L1Loss, Training: \"a|b*\", Validation: \"c|d*\" |||| Vars: FEN, white_active, is_check, is_capture |||| Predictor: CP\n",
    "- E3.1 -> Epochs: 50, Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c*\", Validation: \"d|e|f*\" |||| Vars: FEN, white_active, is_check, is_capture |||| Predictor: CP\n",
    "- E3.2 -> Epochs: 40, Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d*\", Validation: \"d|e|f|g*\" |||| Vars: FEN, white_active, is_check, is_capture |||| Predictor: CP\n",
    "- E4.1 -> Epochs: 25, Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d*\", Validation: \"d|e|f|g*\" |||| Vars: FEN, white_active, is_capture |||| Predictor: CP\n",
    "- E5.1 -> Epochs: 25, NN(1 conv, 2 FC), Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d*\", Validation: \"d|e*\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E5.2 -> Epochs: 50, NN(1 conv, 2 FC), Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d|e*\", Validation: \"e|f*\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E6.1 -> Epochs: 25, NN(2 conv, 2 FC), Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d*\", Validation: \"d|e*\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E6.2 -> Epochs: 50, NN(2 conv, 2 FC), Adam(Learning Rate: 0.006), Loss: L1Loss, Training: \"a|b|c|d|e*\", Validation: \"e|f*\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E7.1 (loaded from 6.2) -> Epochs: 30, NN(2 conv, 2 FC), Adam(Learning Rate: 0.0061), Loss: L1Loss, Training: \"abcdefghijklmnopqr\", Validation: \"adhlp\" |||| Vars: FEN |||| Predictor: CP\n",
    "- E7.2 (loaded from 7.1) -> Epochs: 30, NN(2 conv, 2 FC), Adam(Learning Rate: 0.0061), Loss: L1Loss, Training: \"abcdefghijklmnopqrstuv\", Validation: \"adhlptw\" |||| Vars: FEN |||| Predictor: CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training! (on cuda)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Training Loss: 2.27288, Validation Loss: 1.83541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [1:08:46<33:14:27, 4126.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Training Loss: 1.72504, Validation Loss: 1.74116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [2:17:46<32:09:16, 4134.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Training Loss: 1.61581, Validation Loss: 1.60257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [3:26:39<31:00:09, 4133.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Training Loss: 1.55655, Validation Loss: 1.57295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [4:34:59<29:45:30, 4120.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Training Loss: 1.52528, Validation Loss: 1.52111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [5:43:27<28:35:01, 4116.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Training Loss: 1.50028, Validation Loss: 1.52482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [6:52:11<27:27:26, 4118.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Training Loss: 1.49513, Validation Loss: 1.49897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [8:01:21<26:22:46, 4128.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Training Loss: 1.47289, Validation Loss: 1.48442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [9:09:54<25:12:02, 4123.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Training Loss: 1.46390, Validation Loss: 1.48030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [10:19:02<24:06:00, 4131.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Training Loss: 1.46175, Validation Loss: 1.47036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [11:27:43<22:56:04, 4128.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Training Loss: 1.43921, Validation Loss: 1.48284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [12:36:11<21:45:19, 4122.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Training Loss: 1.43835, Validation Loss: 1.47311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [13:44:32<20:34:40, 4115.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Training Loss: 1.42550, Validation Loss: 1.46174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [14:53:11<19:26:23, 4116.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Training Loss: 1.41554, Validation Loss: 1.45158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [16:02:01<18:18:52, 4120.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Training Loss: 1.40927, Validation Loss: 1.45466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [17:10:45<17:10:25, 4121.73s/it]"
     ]
    }
   ],
   "source": [
    "# Create a dataset\n",
    "dataset1 = lib.ChessIterableDataset(csv_files1)\n",
    "dataset2 = lib.ChessIterableDataset(csv_files2)\n",
    "\n",
    "# Create a data loader\n",
    "train_data_loader = DataLoader(dataset1, batch_size = 15000)\n",
    "val_data_loader = DataLoader(dataset2, batch_size = 15000)\n",
    "\n",
    "# Create a model\n",
    "model = lib.EvalNet()\n",
    "# model = torch.load(f'./models_EL/model_E7-1.pth')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss() # nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.035, momentum=0.9)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0065)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # changed for 8.3\n",
    "\n",
    "# Train the model\n",
    "train_loss_hist, valid_loss_hist = lib.train(model, train_data_loader, val_data_loader, criterion, optimizer, num_epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'model_E{MODEL_NUM}-{MODEL_VERSION}.pth')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_loss_hist, label = 'Training Loss')\n",
    "plt.plot(valid_loss_hist, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim(0, None)\n",
    "plt.title(f'Loss for E{MODEL_NUM}-{MODEL_VERSION} Model')\n",
    "plt.legend()\n",
    "plt.savefig(f'Loss_E{MODEL_NUM}-{MODEL_VERSION}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(train_loss_hist, open(f'pickle/training_loss_history_E{MODEL_NUM}-{MODEL_VERSION}.pkl', 'wb'))\n",
    "pickle.dump(valid_loss_hist, open(f'pickle/validation_loss_history_E{MODEL_NUM}-{MODEL_VERSION}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = torch.load(f'model_E{MODEL_NUM}-{MODEL_VERSION}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move = lib.predict(model_loaded, board.fen())\n",
    "print(move)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board.push_uci(move)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move = lib.predict(model_loaded, board.fen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move = 'e4f6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : make prediction function\n",
    "# TODO : speed up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
